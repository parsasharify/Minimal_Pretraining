{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-27T20:21:22.896955Z",
     "iopub.status.busy": "2024-08-27T20:21:22.896700Z",
     "iopub.status.idle": "2024-08-27T20:21:29.971591Z",
     "shell.execute_reply": "2024-08-27T20:21:29.970585Z",
     "shell.execute_reply.started": "2024-08-27T20:21:22.896932Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T20:21:29.973911Z",
     "iopub.status.busy": "2024-08-27T20:21:29.973483Z",
     "iopub.status.idle": "2024-08-27T20:21:31.418868Z",
     "shell.execute_reply": "2024-08-27T20:21:31.417874Z",
     "shell.execute_reply.started": "2024-08-27T20:21:29.973885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
      "100%|██████████| 83.3M/83.3M [00:00<00:00, 124MB/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MultiTaskResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiTaskResNet50, self).__init__()\n",
    "        self.resnet = models.resnet34(pretrained=True)\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        \n",
    "        self.puzzle_decoder = nn.Sequential(\n",
    "            nn.Linear(1000, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "        self.mag_decoder = nn.Sequential(\n",
    "            nn.Linear(1000, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 4)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "\n",
    "        z_i = self.resnet(x_i)\n",
    "        z_j = self.resnet(x_j)\n",
    "    \n",
    "\n",
    "\n",
    "        y_i = self.mag_decoder(z_i)\n",
    "        y_j = self.puzzle_decoder(z_j)\n",
    "\n",
    "\n",
    "        return y_j, y_i \n",
    "\n",
    "# Example: If task1 has 10 classes and task2 has 4 classes\n",
    "model = MultiTaskResNet50()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T20:21:31.421113Z",
     "iopub.status.busy": "2024-08-27T20:21:31.420181Z",
     "iopub.status.idle": "2024-08-27T20:22:49.912254Z",
     "shell.execute_reply": "2024-08-27T20:22:49.911454Z",
     "shell.execute_reply.started": "2024-08-27T20:21:31.421079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "mag_train_dir = '/kaggle/input/train-mag/train'\n",
    "mag_val_dir = '/kaggle/input/validation-mag/validation'\n",
    "\n",
    "puzzle_train_dir = '/kaggle/input/puzzle-6000/puzzle_6000'\n",
    "puzzle_val_dir = '/kaggle/input/validation-puzzle/validation'\n",
    "\n",
    "mag_dirs = {'train': mag_train_dir,\n",
    "        'validation' : mag_val_dir\n",
    "       }\n",
    "\n",
    "puzzle_dirs = {'train': puzzle_train_dir,\n",
    "        'validation' : puzzle_val_dir\n",
    "       }\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "\n",
    "    'validation':transforms.Compose([\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                            [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "mag_image_datasets = {x: datasets.ImageFolder( mag_dirs[x],   transform=data_transforms[x]) for x in ['train', 'validation']}\n",
    "puzzle_image_datasets = {x: datasets.ImageFolder( puzzle_dirs[x],   transform=data_transforms[x]) for x in ['train', 'validation']}\n",
    "\n",
    "mag_dataloaders = {x: torch.utils.data.DataLoader(mag_image_datasets[x], batch_size=64, shuffle=True, drop_last=True) for x in ['train', 'validation']}\n",
    "puzzle_dataloaders = {x: torch.utils.data.DataLoader(puzzle_image_datasets[x], batch_size=64, shuffle=True, drop_last=True) for x in ['train', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T20:22:49.914561Z",
     "iopub.status.busy": "2024-08-27T20:22:49.914244Z",
     "iopub.status.idle": "2024-08-27T20:22:49.964452Z",
     "shell.execute_reply": "2024-08-27T20:22:49.963489Z",
     "shell.execute_reply.started": "2024-08-27T20:22:49.914534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T20:22:49.966159Z",
     "iopub.status.busy": "2024-08-27T20:22:49.965760Z",
     "iopub.status.idle": "2024-08-27T20:22:50.183583Z",
     "shell.execute_reply": "2024-08-27T20:22:50.182809Z",
     "shell.execute_reply.started": "2024-08-27T20:22:49.966126Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T20:22:50.185055Z",
     "iopub.status.busy": "2024-08-27T20:22:50.184719Z",
     "iopub.status.idle": "2024-08-27T20:22:50.189283Z",
     "shell.execute_reply": "2024-08-27T20:22:50.188398Z",
     "shell.execute_reply.started": "2024-08-27T20:22:50.185024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion_task1 = nn.CrossEntropyLoss()\n",
    "criterion_task2 = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T20:22:50.190733Z",
     "iopub.status.busy": "2024-08-27T20:22:50.190312Z",
     "iopub.status.idle": "2024-08-27T20:22:50.198738Z",
     "shell.execute_reply": "2024-08-27T20:22:50.197802Z",
     "shell.execute_reply.started": "2024-08-27T20:22:50.190704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "class GatherLayer(torch.autograd.Function):\n",
    "    \"\"\"Gather tensors from all process, supporting backward propagation.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        output = [torch.zeros_like(input) for _ in range(dist.get_world_size())]\n",
    "        dist.all_gather(output, input)\n",
    "        return tuple(output)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, *grads):\n",
    "        (input,) = ctx.saved_tensors\n",
    "        grad_out = torch.zeros_like(input)\n",
    "        grad_out[:] = grads[dist.get_rank()]\n",
    "        return grad_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T20:22:50.200416Z",
     "iopub.status.busy": "2024-08-27T20:22:50.200006Z",
     "iopub.status.idle": "2024-08-27T20:22:50.213865Z",
     "shell.execute_reply": "2024-08-27T20:22:50.212896Z",
     "shell.execute_reply.started": "2024-08-27T20:22:50.200383Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "class NT_Xent(nn.Module):\n",
    "    def __init__(self, batch_size, temperature, world_size):\n",
    "        super(NT_Xent, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.world_size = world_size\n",
    "\n",
    "        self.mask = self.mask_correlated_samples(batch_size, world_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
    "\n",
    "    def mask_correlated_samples(self, batch_size, world_size):\n",
    "        N = 2 * batch_size * world_size\n",
    "        mask = torch.ones((N, N), dtype=bool)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        for i in range(batch_size * world_size):\n",
    "            mask[i, batch_size * world_size + i] = 0\n",
    "            mask[batch_size * world_size + i, i] = 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        \"\"\"\n",
    "        We do not sample negative examples explicitly.\n",
    "        Instead, given a positive pair, similar to (Chen et al., 2017), we treat the other 2(N − 1) augmented examples within a minibatch as negative examples.\n",
    "        \"\"\"\n",
    "        N = 2 * self.batch_size * self.world_size\n",
    "\n",
    "        if self.world_size > 1:\n",
    "            z_i = torch.cat(GatherLayer.apply(z_i), dim=0)\n",
    "            z_j = torch.cat(GatherLayer.apply(z_j), dim=0)\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "\n",
    "        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n",
    "\n",
    "        sim_i_j = torch.diag(sim, self.batch_size * self.world_size)\n",
    "        sim_j_i = torch.diag(sim, -self.batch_size * self.world_size)\n",
    "\n",
    "        # We have 2N samples, but with Distributed training every GPU gets N examples too, resulting in: 2xNxN\n",
    "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
    "        negative_samples = sim[self.mask].reshape(N, -1)\n",
    "\n",
    "        labels = torch.zeros(N).to(positive_samples.device).long()\n",
    "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss /= N\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T20:22:50.215154Z",
     "iopub.status.busy": "2024-08-27T20:22:50.214876Z",
     "iopub.status.idle": "2024-08-27T20:22:50.224193Z",
     "shell.execute_reply": "2024-08-27T20:22:50.223328Z",
     "shell.execute_reply.started": "2024-08-27T20:22:50.215130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temperature = .5\n",
    "batch_size = 64\n",
    "\n",
    "#criterion_task1 = NT_Xent(batch_size, temperature, world_size=1)\n",
    "#criterion_task2 = NT_Xent(batch_size, temperature, world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T20:22:50.225511Z",
     "iopub.status.busy": "2024-08-27T20:22:50.225211Z",
     "iopub.status.idle": "2024-08-27T20:22:50.232418Z",
     "shell.execute_reply": "2024-08-27T20:22:50.231670Z",
     "shell.execute_reply.started": "2024-08-27T20:22:50.225481Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T20:22:50.235849Z",
     "iopub.status.busy": "2024-08-27T20:22:50.235358Z",
     "iopub.status.idle": "2024-08-27T20:22:50.257041Z",
     "shell.execute_reply": "2024-08-27T20:22:50.256145Z",
     "shell.execute_reply.started": "2024-08-27T20:22:50.235824Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_validation(model, num_epochs, puzzle_dataloaders, mag_dataloaders, optimizer, criterion_task1, criterion_task2, device, l1_lambda, saving_name):\n",
    "    hold_loss = []\n",
    "    hold_loss1 = []\n",
    "    hold_accuracy1 = []\n",
    "    \n",
    "    hold_loss2 = []\n",
    "    hold_accuracy2 = []\n",
    "\n",
    "    # Learning rate scheduler for potential learning rate decay\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_loss_task1 = 0.0\n",
    "        running_loss_task2 = 0.0\n",
    "\n",
    "        for i, ((data_task1, target_task1), (data_task2, target_task2)) in enumerate(zip(puzzle_dataloaders['train'], mag_dataloaders['train'])):\n",
    "            data_task1, target_task1 = data_task1.to(device), target_task1.to(device)\n",
    "            data_task2, target_task2 = data_task2.to(device), target_task2.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output_task1, output_task2 = model(data_task1, data_task2)\n",
    "            \n",
    "            loss_task1 = criterion_task1(output_task1, target_task1)\n",
    "            loss_task2 = criterion_task2(output_task2, target_task2)\n",
    "            \n",
    "            base_loss = loss_task1 + loss_task2\n",
    "\n",
    "            # Add L1 regularization\n",
    "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            loss = base_loss + l1_lambda * l1_norm  # Total loss including L1 penalty\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_loss_task1 += loss_task1.item()\n",
    "            running_loss_task2 += loss_task2.item()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}], Loss: {running_loss / 100:.4f}, Loss Task1: {running_loss_task1 / 100:.4f}, Loss Task2: {running_loss_task2 / 100:.4f}\")\n",
    "                hold_loss.append(running_loss / 100)\n",
    "                running_loss = 0.0\n",
    "                running_loss_task1 = 0.0\n",
    "                running_loss_task2 = 0.0\n",
    "        \n",
    "        # Adjust learning rate based on the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()  \n",
    "        total_correct1 = 0\n",
    "        total_samples1 = 0\n",
    "        \n",
    "        total_correct2 = 0\n",
    "        total_samples2 = 0\n",
    "        \n",
    "        results1 = defaultdict(list)\n",
    "        results2 = defaultdict(list)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for (data_task1, target_task1), (data_task2, target_task2) in zip(puzzle_dataloaders['validation'], mag_dataloaders['validation']):\n",
    "                data_task1, target_task1 = data_task1.to(device), target_task1.to(device)\n",
    "                data_task2, target_task2 = data_task2.to(device), target_task2.to(device)\n",
    "                \n",
    "                output_task1, output_task2 = model(data_task1, data_task2)\n",
    "                \n",
    "                predicted1 = output_task1.argmax(1)\n",
    "                predicted2 = output_task2.argmax(1)\n",
    "                \n",
    "                total_correct1 += (predicted1 == target_task1).sum().item()\n",
    "                total_samples1 += target_task1.size(0)\n",
    "                \n",
    "                total_correct2 += (predicted2 == target_task2).sum().item()\n",
    "                total_samples2 += target_task2.size(0)\n",
    "\n",
    "                for label, pred in zip(target_task1.cpu().numpy(), predicted1.cpu().numpy()):\n",
    "                    key = f\"{label}\"\n",
    "                    results1[key].append(pred == label)\n",
    "                \n",
    "                for label, pred in zip(target_task2.cpu().numpy(), predicted2.cpu().numpy()):\n",
    "                    key = f\"{label}\"\n",
    "                    results2[key].append(pred == label)\n",
    "\n",
    "        # Calculate accuracy for task 1 and task 2\n",
    "        add_list1 = []\n",
    "        add_list2 = []\n",
    "        \n",
    "        for key, values in results1.items():\n",
    "            accuracy = sum(values) / len(values)\n",
    "            add_list1.append(f\"Accuracy for {key}: {accuracy:.2f}\")\n",
    "        hold_accuracy1.append(add_list1)\n",
    "\n",
    "        total_accuracy1 = total_correct1 / total_samples1\n",
    "        print(f\"Total Accuracy Task 1: {total_accuracy1:.2f}\")\n",
    "\n",
    "        for key, values in results2.items():\n",
    "            accuracy = sum(values) / len(values)\n",
    "            add_list2.append(f\"Accuracy for {key}: {accuracy:.2f}\")\n",
    "        hold_accuracy2.append(add_list2)\n",
    "\n",
    "        total_accuracy2 = total_correct2 / total_samples2\n",
    "        print(f\"Total Accuracy Task 2: {total_accuracy2:.2f}\")\n",
    "        print(\"----------------------------------\")\n",
    "        \n",
    "        if (epoch+1)%10 == 0:\n",
    "            # Save model with a more informative name\n",
    "            save_filename = f\"{saving_name}resnet34model_puzzle_mag_epoch_{epoch+1}.pth\"#saving_name# f\"{saving_name}_epoch_{epoch+1}_acc1_{total_accuracy1:.2f}_acc2_{total_accuracy2:.2f}.pth\"\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            }, save_filename)\n",
    "            print(f\"Model saved as {save_filename}!\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    return hold_loss, hold_accuracy1, hold_accuracy2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-27T20:22:50.259093Z",
     "iopub.status.busy": "2024-08-27T20:22:50.258764Z",
     "iopub.status.idle": "2024-08-27T20:38:36.475940Z",
     "shell.execute_reply": "2024-08-27T20:38:36.474974Z",
     "shell.execute_reply.started": "2024-08-27T20:22:50.259069Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100], Loss: 2.8507, Loss Task1: 0.8900, Loss Task2: 1.9608\n",
      "Epoch [1/1], Step [200], Loss: 2.6971, Loss Task1: 0.7447, Loss Task2: 1.9524\n",
      "Epoch [1/1], Step [300], Loss: 2.6896, Loss Task1: 0.7396, Loss Task2: 1.9499\n",
      "Epoch [1/1], Step [400], Loss: 2.6913, Loss Task1: 0.7427, Loss Task2: 1.9486\n",
      "Epoch [1/1], Step [500], Loss: 2.7016, Loss Task1: 0.7536, Loss Task2: 1.9480\n",
      "Epoch [1/1], Step [600], Loss: 2.6989, Loss Task1: 0.7514, Loss Task2: 1.9475\n",
      "Epoch [1/1], Step [700], Loss: 2.6823, Loss Task1: 0.7354, Loss Task2: 1.9469\n",
      "Total Accuracy Task 1: 0.10\n",
      "Total Accuracy Task 2: 0.15\n",
      "----------------------------------\n",
      "Model saved as /kaggle/working/50epoch_resnet34model_dbracs_mag.pth!\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "hold_loss, hold_accuracy1, hold_accuracy2 = train_validation(model, 50, puzzle_dataloaders, mag_dataloaders, optimizer, criterion_task1, criterion_task2, device, 0, '/kaggle/working/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hold_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hold_accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hold_accuracy2)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5528829,
     "sourceId": 9152547,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5529030,
     "sourceId": 9152827,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5529181,
     "sourceId": 9153050,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5534467,
     "sourceId": 9160678,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5593806,
     "sourceId": 9246736,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5593862,
     "sourceId": 9246812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
