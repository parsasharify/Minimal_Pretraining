{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-25T20:09:15.221030Z",
     "iopub.status.busy": "2024-11-25T20:09:15.220058Z",
     "iopub.status.idle": "2024-11-25T20:09:15.225933Z",
     "shell.execute_reply": "2024-11-25T20:09:15.224997Z",
     "shell.execute_reply.started": "2024-11-25T20:09:15.220993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T20:16:27.184509Z",
     "iopub.status.busy": "2024-11-25T20:16:27.183821Z",
     "iopub.status.idle": "2024-11-25T20:16:31.712273Z",
     "shell.execute_reply": "2024-11-25T20:16:31.711510Z",
     "shell.execute_reply.started": "2024-11-25T20:16:27.184463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:02<00:00, 200MB/s]  \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "# Define the VGG19-based model with two classification heads\n",
    "class DualHeadVGG19Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DualHeadVGG19Model, self).__init__()\n",
    "        # Load pre-trained VGG19\n",
    "        self.base_model = models.vgg19(pretrained=True).features\n",
    "        \n",
    "        # Freeze the base model layers\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # Add global average pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Add classification heads\n",
    "        self.fc4 = nn.Linear(512, 4)   # Head for 4-class dataset\n",
    "        self.fc10 = nn.Linear(512, 10) # Head for 10-class dataset\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x_i = self.base_model(x_i)  # VGG19 feature extraction\n",
    "        x_i = self.global_avg_pool(x_i)  # Global average pooling\n",
    "        x_i = x_i.view(x_i.size(0), -1)  # Flatten\n",
    "        out4 = self.fc4(x_i)  # 4-class output\n",
    "       \n",
    "\n",
    "        x_j = self.base_model(x_j)  # VGG19 feature extraction\n",
    "        x_j = self.global_avg_pool(x_j)  # Global average pooling\n",
    "        x_j = x_j.view(x_j.size(0), -1)  # Flatten\n",
    "       \n",
    "        out10 = self.fc10(x_j)  # 10-class output\n",
    "        return out10, out4\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "model = DualHeadVGG19Model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T20:16:31.713848Z",
     "iopub.status.busy": "2024-11-25T20:16:31.713578Z",
     "iopub.status.idle": "2024-11-25T20:17:01.870214Z",
     "shell.execute_reply": "2024-11-25T20:17:01.869524Z",
     "shell.execute_reply.started": "2024-11-25T20:16:31.713821Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "mag_train_dir = '/kaggle/input/train-mag/train'\n",
    "mag_val_dir = '/kaggle/input/validation-mag/validation'\n",
    "\n",
    "puzzle_train_dir = '/kaggle/input/puzzle-6000/puzzle_6000'\n",
    "puzzle_val_dir = '/kaggle/input/validation-puzzle/validation'\n",
    "\n",
    "mag_dirs = {'train': mag_train_dir,\n",
    "        'validation' : mag_val_dir\n",
    "       }\n",
    "\n",
    "puzzle_dirs = {'train': puzzle_train_dir,\n",
    "        'validation' : puzzle_val_dir\n",
    "       }\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "\n",
    "    'validation':transforms.Compose([\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                            [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "mag_image_datasets = {x: datasets.ImageFolder( mag_dirs[x],   transform=data_transforms[x]) for x in ['train', 'validation']}\n",
    "puzzle_image_datasets = {x: datasets.ImageFolder( puzzle_dirs[x],   transform=data_transforms[x]) for x in ['train', 'validation']}\n",
    "\n",
    "mag_dataloaders = {x: torch.utils.data.DataLoader(mag_image_datasets[x], batch_size=64, shuffle=True, drop_last=True) for x in ['train', 'validation']}\n",
    "puzzle_dataloaders = {x: torch.utils.data.DataLoader(puzzle_image_datasets[x], batch_size=64, shuffle=True, drop_last=True) for x in ['train', 'validation']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T20:17:01.871423Z",
     "iopub.status.busy": "2024-11-25T20:17:01.871163Z",
     "iopub.status.idle": "2024-11-25T20:17:01.876403Z",
     "shell.execute_reply": "2024-11-25T20:17:01.875479Z",
     "shell.execute_reply.started": "2024-11-25T20:17:01.871396Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T20:17:01.878398Z",
     "iopub.status.busy": "2024-11-25T20:17:01.878101Z",
     "iopub.status.idle": "2024-11-25T20:17:01.903952Z",
     "shell.execute_reply": "2024-11-25T20:17:01.903339Z",
     "shell.execute_reply.started": "2024-11-25T20:17:01.878354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T20:17:01.904998Z",
     "iopub.status.busy": "2024-11-25T20:17:01.904776Z",
     "iopub.status.idle": "2024-11-25T20:17:01.908915Z",
     "shell.execute_reply": "2024-11-25T20:17:01.908006Z",
     "shell.execute_reply.started": "2024-11-25T20:17:01.904975Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "criterion_task1 = nn.CrossEntropyLoss()\n",
    "criterion_task2 = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T20:17:01.910169Z",
     "iopub.status.busy": "2024-11-25T20:17:01.909890Z",
     "iopub.status.idle": "2024-11-25T20:17:01.919532Z",
     "shell.execute_reply": "2024-11-25T20:17:01.918776Z",
     "shell.execute_reply.started": "2024-11-25T20:17:01.910144Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "\n",
    "\n",
    "class NT_Xent(nn.Module):\n",
    "    def __init__(self, batch_size, temperature, world_size):\n",
    "        super(NT_Xent, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.temperature = temperature\n",
    "        self.world_size = world_size\n",
    "\n",
    "        self.mask = self.mask_correlated_samples(batch_size, world_size)\n",
    "        self.criterion = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "        self.similarity_f = nn.CosineSimilarity(dim=2)\n",
    "\n",
    "    def mask_correlated_samples(self, batch_size, world_size):\n",
    "        N = 2 * batch_size * world_size\n",
    "        mask = torch.ones((N, N), dtype=bool)\n",
    "        mask = mask.fill_diagonal_(0)\n",
    "        for i in range(batch_size * world_size):\n",
    "            mask[i, batch_size * world_size + i] = 0\n",
    "            mask[batch_size * world_size + i, i] = 0\n",
    "        return mask\n",
    "\n",
    "    def forward(self, z_i, z_j):\n",
    "        \"\"\"\n",
    "        We do not sample negative examples explicitly.\n",
    "        Instead, given a positive pair, similar to (Chen et al., 2017), we treat the other 2(N − 1) augmented examples within a minibatch as negative examples.\n",
    "        \"\"\"\n",
    "        N = 2 * self.batch_size * self.world_size\n",
    "\n",
    "        if self.world_size > 1:\n",
    "            z_i = torch.cat(GatherLayer.apply(z_i), dim=0)\n",
    "            z_j = torch.cat(GatherLayer.apply(z_j), dim=0)\n",
    "        z = torch.cat((z_i, z_j), dim=0)\n",
    "\n",
    "        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature\n",
    "\n",
    "        sim_i_j = torch.diag(sim, self.batch_size * self.world_size)\n",
    "        sim_j_i = torch.diag(sim, -self.batch_size * self.world_size)\n",
    "\n",
    "        # We have 2N samples, but with Distributed training every GPU gets N examples too, resulting in: 2xNxN\n",
    "        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)\n",
    "        negative_samples = sim[self.mask].reshape(N, -1)\n",
    "\n",
    "        labels = torch.zeros(N).to(positive_samples.device).long()\n",
    "        logits = torch.cat((positive_samples, negative_samples), dim=1)\n",
    "        loss = self.criterion(logits, labels)\n",
    "        loss /= N\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T20:17:01.920653Z",
     "iopub.status.busy": "2024-11-25T20:17:01.920388Z",
     "iopub.status.idle": "2024-11-25T20:17:01.931356Z",
     "shell.execute_reply": "2024-11-25T20:17:01.930551Z",
     "shell.execute_reply.started": "2024-11-25T20:17:01.920629Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "temperature = .5\n",
    "batch_size = 64\n",
    "\n",
    "#criterion_task1 = NT_Xent(batch_size, temperature, world_size=1)\n",
    "#criterion_task2 = NT_Xent(batch_size, temperature, world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T20:17:01.932676Z",
     "iopub.status.busy": "2024-11-25T20:17:01.932400Z",
     "iopub.status.idle": "2024-11-25T20:17:01.940472Z",
     "shell.execute_reply": "2024-11-25T20:17:01.939447Z",
     "shell.execute_reply.started": "2024-11-25T20:17:01.932651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T20:17:01.941825Z",
     "iopub.status.busy": "2024-11-25T20:17:01.941577Z",
     "iopub.status.idle": "2024-11-25T20:17:01.957542Z",
     "shell.execute_reply": "2024-11-25T20:17:01.956736Z",
     "shell.execute_reply.started": "2024-11-25T20:17:01.941800Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_validation(model, num_epochs, puzzle_dataloaders, mag_dataloaders, optimizer, criterion_task1, criterion_task2, device, l1_lambda, saving_name):\n",
    "    hold_loss = []\n",
    "    hold_loss1 = []\n",
    "    hold_accuracy1 = []\n",
    "    \n",
    "    hold_loss2 = []\n",
    "    hold_accuracy2 = []\n",
    "\n",
    "    # Learning rate scheduler for potential learning rate decay\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_loss_task1 = 0.0\n",
    "        running_loss_task2 = 0.0\n",
    "\n",
    "        for i, ((data_task1, target_task1), (data_task2, target_task2)) in enumerate(zip(puzzle_dataloaders['train'], mag_dataloaders['train'])):\n",
    "            data_task1, target_task1 = data_task1.to(device), target_task1.to(device)\n",
    "            data_task2, target_task2 = data_task2.to(device), target_task2.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output_task1, output_task2 = model(data_task1, data_task2)\n",
    "            \n",
    "            loss_task1 = criterion_task1(output_task1, target_task1)\n",
    "            loss_task2 = criterion_task2(output_task2, target_task2)\n",
    "            \n",
    "            base_loss = loss_task1 + loss_task2\n",
    "\n",
    "            # Add L1 regularization\n",
    "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            loss = base_loss + l1_lambda * l1_norm  # Total loss including L1 penalty\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_loss_task1 += loss_task1.item()\n",
    "            running_loss_task2 += loss_task2.item()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}], Loss: {running_loss / 100:.4f}, Loss Task1: {running_loss_task1 / 100:.4f}, Loss Task2: {running_loss_task2 / 100:.4f}\")\n",
    "                hold_loss.append(running_loss / 100)\n",
    "                running_loss = 0.0\n",
    "                running_loss_task1 = 0.0\n",
    "                running_loss_task2 = 0.0\n",
    "        \n",
    "        # Adjust learning rate based on the scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()  \n",
    "        total_correct1 = 0\n",
    "        total_samples1 = 0\n",
    "        \n",
    "        total_correct2 = 0\n",
    "        total_samples2 = 0\n",
    "        \n",
    "        results1 = defaultdict(list)\n",
    "        results2 = defaultdict(list)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for (data_task1, target_task1), (data_task2, target_task2) in zip(puzzle_dataloaders['validation'], mag_dataloaders['validation']):\n",
    "                data_task1, target_task1 = data_task1.to(device), target_task1.to(device)\n",
    "                data_task2, target_task2 = data_task2.to(device), target_task2.to(device)\n",
    "                \n",
    "                output_task1, output_task2 = model(data_task1, data_task2)\n",
    "                \n",
    "                predicted1 = output_task1.argmax(1)\n",
    "                predicted2 = output_task2.argmax(1)\n",
    "                \n",
    "                total_correct1 += (predicted1 == target_task1).sum().item()\n",
    "                total_samples1 += target_task1.size(0)\n",
    "                \n",
    "                total_correct2 += (predicted2 == target_task2).sum().item()\n",
    "                total_samples2 += target_task2.size(0)\n",
    "\n",
    "                for label, pred in zip(target_task1.cpu().numpy(), predicted1.cpu().numpy()):\n",
    "                    key = f\"{label}\"\n",
    "                    results1[key].append(pred == label)\n",
    "                \n",
    "                for label, pred in zip(target_task2.cpu().numpy(), predicted2.cpu().numpy()):\n",
    "                    key = f\"{label}\"\n",
    "                    results2[key].append(pred == label)\n",
    "\n",
    "        # Calculate accuracy for task 1 and task 2\n",
    "        add_list1 = []\n",
    "        add_list2 = []\n",
    "        \n",
    "        for key, values in results1.items():\n",
    "            accuracy = sum(values) / len(values)\n",
    "            add_list1.append(f\"Accuracy for {key}: {accuracy:.2f}\")\n",
    "        hold_accuracy1.append(add_list1)\n",
    "\n",
    "        total_accuracy1 = total_correct1 / total_samples1\n",
    "        print(f\"Total Accuracy Task 1: {total_accuracy1:.2f}\")\n",
    "\n",
    "        for key, values in results2.items():\n",
    "            accuracy = sum(values) / len(values)\n",
    "            add_list2.append(f\"Accuracy for {key}: {accuracy:.2f}\")\n",
    "        hold_accuracy2.append(add_list2)\n",
    "\n",
    "        total_accuracy2 = total_correct2 / total_samples2\n",
    "        print(f\"Total Accuracy Task 2: {total_accuracy2:.2f}\")\n",
    "        print(\"----------------------------------\")\n",
    "        \n",
    "        if (epoch+1)%10 == 0:\n",
    "            # Save model with a more informative name\n",
    "            save_filename = f\"{saving_name}resnet34model_puzzle_mag_epoch_{epoch+1}.pth\"#saving_name# f\"{saving_name}_epoch_{epoch+1}_acc1_{total_accuracy1:.2f}_acc2_{total_accuracy2:.2f}.pth\"\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            }, save_filename)\n",
    "            print(f\"Model saved as {save_filename}!\")\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "    return hold_loss, hold_accuracy1, hold_accuracy2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hold_loss, hold_accuracy1, hold_accuracy2 = train_validation(model, 50, puzzle_dataloaders, mag_dataloaders, optimizer, criterion_task1, criterion_task2, device, 0, '/kaggle/working/')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5528829,
     "sourceId": 9152547,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5529030,
     "sourceId": 9152827,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5529171,
     "sourceId": 9153037,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5529181,
     "sourceId": 9153050,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5534467,
     "sourceId": 9160678,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5593806,
     "sourceId": 9246736,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5593862,
     "sourceId": 9246812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
